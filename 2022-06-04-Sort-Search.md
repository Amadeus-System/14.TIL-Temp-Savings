

# Chapter 7. 정렬과 탐색

## 7.1 정렬이란?

우리가 데이터를 저장하기 위해 복잡한 자료구조를 사용하는 이유는 무엇일까? 대부분의 경우는 효율적인 탐색과 정렬을 위해서이다. **탐색(Searching)**은 많은 자료 중에서 무언가를 찾는 작업이고, **정렬(Sorting)**은 데이터를 순서대로 재배열하는 것을 말한다. 이들은 컴퓨터에서 가장 중요한 응용으로 효율적인 탐색과 정렬을 위해서는 적절한 자료구조가 반드시 요구된다. 이 장에서는 간단한 정렬과 탐색 방법들을 알아보자. 복잡한 정렬 방법들은 12장에서 다룬다.




정렬을 위해서는 사물들을 서로 **비교**할 수 있어야 한다. **비교할 수 있는 모든 속성**들은 **정렬의 기준**이 될 수 있다. 예를 들어, 다음 그림은 말들을 키 순서대로 정렬한 것인데, 나이순으로 정렬한다면 다른 결과가 나올 것이다. 이때 순서에는 **오름차순(Ascending Order)**과 **내림차순(Descending Order)**이 있다.


정렬은 자료의 탐색에서도 매우 중요하다. 사전에서 우리가 단어를 쉽게 찾을 수 있는 것은 단어들이 **알파벳**순으로 정렬되어 있기 때문이다. 만약 사전이 정렬되어 있지 않다면 어떤 단어를 빨리 찾는 것은 거의 불가능할 것이다. 컴퓨터도 마찬가지이다. 정렬되어 있지 않은 자료에 대해서는 탐색의 효율이 크게 떨어진다.




정렬시켜야 할 대상을 보통 **레코드(Record)**라고 부른다. 또한 레코드는 여러개의 **필드(Field)**로 이루어진다. 예를 들어, 경주마의 경우 번호, 이름, 키, 나이, 품종, 연락처 등의 여러 속성들이 있는데, 이들이 필드가 된다. 또한, 이들 중에서 정렬의 기준이 되는 필드를 **키(Key)** 또는 **정렬 키(Sort Key)**라고 한다. 결국 **정렬이란 레코드들을 키(Key)의 순서로 재배열**하는 것이다.


[그림 7.1] 정렬의 대상인 레코드와 필드, 키의 개념


### 정렬 장소에 따른 분류

* **내부(Internal) 정렬** : 모든 데이터가 메인 메모리에 올라와 있는 정렬을 의미한다. 이 책에서는 내부 정렬만을 다룬다.
* **외부(External) 정렬** : 외부 기억장치에 대부분의 데이터가 있고, 일부만 메모리에 올려 정렬하는 방법으로 대용량 자료를 정렬하기 위해 사용한다.


### 구현복잡도와 알고리즘 효율성에 따른 분류

* 단순하지만 비효율적인 방법 : 삽입정렬, 선택정렬, 버블정렬 등
* 복잡하지만 효율적인 방법 : 퀵 정렬, 힙 정렬, 병합정렬, 기수 정렬 등


### 안정성에 따른 분류

**안정성(Stability)**이란 입력 데이터에 동일한 키 값을 갖는 레코드가 여러개 존재할 경우, 정렬 후에도 이들의 상대적인 위치가 바뀌지 않는 것을 말한다. 안정성을 충족하는 정렬에는 삽입정렬, 버블정렬, 병합정렬 등이 있다.

[그림 7.2] 안정성을 충족하지 않는 정렬의 예



## 7.2 간단한 정렬 알고리즘

### 선택 정렬(Selection Sort)

**선택 정렬**은 리스트에서 가장 작은 숫자를 선택해서 앞쪽으로 옮기는 방법을 사용한다. 전체 숫자들은 아직 정렬되지 않은 **오른쪽 리스트**와 정렬이 완료된 **왼쪽 리스트**로 나누어지는데, 맨 처음에는 모든 숫자가 오른쪽 리스트에 들어있다. 선택 정렬은 **오른쪽 리스트에서 가장 작은 숫자를 선택하여 왼쪽 리스트의 맨 뒤로 이동하는 작업**을 반복하는 것이다. 다음 표와 같이 이 과정은 오른쪽 리스트가 공백상태가 될 때까지 되풀이된다.




실제로 선택정렬을 구현하기 위해 2개의 배열을 사용할 필요는 없다. 정렬이 안 된 리스트에서 최소값이 선택되면 이 값을 배열의 첫번째 요소와 **교환**하면 되기 때문이다. 예를 들어, 다음 그림에서 최소값 1과 첫번째 요소 5를 교환하면 전체 배열은 정렬된 부분과 되지 않은 부분으로 나뉜다. 다음에는 2번째 요소부터 나머지들 중에서 가장 작은 값을 선택하고 선택된 값을 2번째 요소와 교환한다. 전체 요소의 개수가 $n$이면 이 절차를 $n-1$번 반복하면 전체 리스트가 정렬된다.



[그림 7.3] 선택 정렬의 과정


선택 정렬 알고리즘을 파이썬 함수로 구현한 코드는 다음과 같다. 최소 항목을 찾는 범위와 튜플을 이용해 배열의 두 항목을 서로 교환하는 코드에 유의하라.

``` Python
def selection_sort(A):                      # 선택 정렬
    n = len(A)                              # n : 리스트 A의 길이
    for i in range(n - 1):                  # 0, 1, 2, ..., n-2 [외부루프]
        least = i
        for j in range(i + 1, n):           # i+1, ..., n-1 [내부루프]
            if A[j] < A[least]:             # 비교연산
                least = j                   # 최소항목 갱신
        A[i], A[least] = A[least], A[i]     # 배열 항목 교환
        printStep(A, i + 1)                 # 중간과정 출력용 문장
```

정렬의 각 단계에서 현재 리스트의 정렬 상태를 출력해보기 위한 다음 함수는 다른 정렬 알고리즘에서도 사용할 것이다.

``` Python
def printStep(arr, val):                    # 중간과정 출력용 함수
    print('Step %2d =' % val, end = '')
    print(arr)
```


선택 정렬 알고리즘의 테스트 프로그램과 실행결과는 다음과 같다. 입력 리스트의 정렬 전과 후의 상태와 함께, 알고리즘의 각 단계별 리스트 상태를 출력하고 있다.

``` Python
data = [5, 3, 8, 4, 9, 1, 6, 2, 7]
print('Original :', data)
selection_sort(data)
print('Selection :', data)
```







선택 정렬은 입력 배열 이외의 추가적인 배열을 사용하지 않는다. 이러한 정렬 방법을 **제자리 정렬(In-place Sorting)**이라 한다.

선택정렬의 시간복잡도를 분석해보자. 정렬 함수에서 이중루프가 사용되는데, 외부루프는 $n-1$번 반복하고, 내부루프는 0에서 $n-2$까지 변하는 $i$에 대하여 $(n-1)-i$번 반복된다. 따라서 전체 비교횟수는 다음과 같다.

$$ (n-1) + (n-2) + ... + 1 = n (n-1) / 2 = O(n^2) $$

결국, 선택 정렬은 시간복잡도가 $O(n^2)$으로 효율적인 알고리즘도 아니고 안정성을 만족하지도 않는다. 그러나 알고리즘이 간단하고, 입력자료의 구성과 상관없이 **자료이동 횟수가 결정**된다는 장점을 갖는다.


### 삽입 정렬(Insertion Sort)

삽입 정렬은 카드를 정렬하는 방법과 유사하다. 손 안에 정렬된 카드가 있고, 카드를 추가로 1장씩 더 받을 때마다 그 카드를 순서대로 끼워넣는 것이다. 물론 삽입 후에도 전체 카드는 정렬이 되어 있어야 한다. 이 과정을 새로 받는 모든 카드에 대해 수행하면 전체 카드가 정렬된다.


[그림 7.4] 삽입 정렬의 원리


배열에서도 마찬가지이다. 정렬이 안 된 부분의 숫자를 하나씩 정렬된 부분의 적절한 위치를 찾아 끼워넣는 과정을 반복한다. 한 번의 삽입이 끝나면 정렬이 안 된 부분의 항목수가 하나 줄어드는데, 이 과정을 정렬되지 않은 항목이 하나도 없을 때까지 반복하면 정렬이 끝난다. 그런데, 숫자를 **끼워 넣는** 과정이 문제이다. 예를 들어, 그림에서 4를 3과 5 사이에 삽입하기 위해서는 4보다 큰 항목들(8, 5)을 모두 **한 칸씩 뒤쪽으로 이동**해야 한다. 특히 이 과정은 정렬된 부분의 **맨 뒤쪽 항목부터 처리**해야 되는 것에 유의하라. 다음은 [5, 3, 8, 4, 9, 1, 6, 2, 7]을 삽입 정렬하는 과정을 보여준다.




[그림 7.5] 삽입 정렬의 과정




삽입정렬 알고리즘과 실행결과는 다음과 같다.

``` Python
def insertion_sort(A):                  # 선택 정렬
    n = len(A)
    for i in range(1, n):               # 외부 루프 : 1, 2, ..., n-1
        key = A[i]
        j = i - 1
        while j >= 0 and A[j] > key:    # 내부 루프
            A[j + 1] = A[j]             # 항목들을 뒤로 1칸씩 이동
            j -= 1
        A[j + 1] = key                  # 항목 삽입
        printStep(A, i)
```



삽입 정렬의 **복잡도는 입력 자료의 구성에 따라서 달라진다**. 먼저 입력 자료가 이미 **정렬되어 있는 경우는 가장 빠르다**. 내부 루프가 모든 항목에서 1번만에 빠져나올 것이기 때문이다. 삽입 정렬의 외부 루프는 $n-1$번 실행되고 각 단계에서 1번의 비교와 2번의 이동만 이루어지므로 총 비교 횟수는 $n-1$번, 총 이동 횟수는 $2(n-1)$번이 되어 이 경우의 시간복잡도는 $O(n)$이다.

**최악의 경우는 입력 자료가 역으로 정렬된 경우이다**. 각 단계에서 앞에 놓인 자료들은 전부 1칸씩 뒤로 이동하여야 한다. 따라서 외부 루프 안의 각 반복마다 $i$번의 비교가 수행되므로 총 비교 횟수는 다음과 같다. 


$$ \sum_{i=0}^{n-1} i = 1 + 2 + ... + (n - 1) = \frac {n (n-1)}{2} = O(n^2) $$

삽입 정렬은 시간 복잡도가 $O(n^2)$인데, 특히 많은 **레코드들의 이동을 포함**하므로 레코드의 크기가 크고 양이 많은 경우 효율적이지 않다. 반면에 알고리즘이 간단하므로 레코드의 수가 적을 경우 효과적이다. 특히 **대부분의 레코드가 이미 정렬되어 있는 경우 효율적**으로 사용될 수 있다.


### 버블 정렬(Bubble Sort)

인접한 2개의 레코드를 비교하여 크기가 순서대로가 아니면 서로 교환하는 방법을 사용한다. 이러한 **비교-교환 과정**은 리스트의 왼쪽 끝에서 시작하여 오른쪽 끝까지 진행한다. 비교-교환 과정이 1번 완료되면 (1번의 스캔) 가장 큰 레코드가 리스트의 오른쪽 끝으로 이동된다. 이것은 마치 물속에서 거품(Bubble)이 보글보글 떠오르는 것과 유사하여 버블정렬이라 부른다. 비교-교환 과정은 더 이상 교환이 일어나지 않을 때까지 계속된다.

다음은 버블 정렬의 1번의 스캔 과정을 보여준다. 먼저 5와 3을 비교하면 5가 더 크므로 서로 교환하고, 다음으로 5와 8을 비교하면 8이 더 크므로 교환없이 다음 단계로 진행한다. 이러한 과정이 반복되면 배열에서 가장 큰 값인 9가 오른쪽 끝으로 이동하게 된다.



[그림 7.6] 버블 정렬의 과정



리스트를 1번 스캔하면 오른쪽 끝에 가장 큰 레코드가 위치하게 되고 전체 리스트는 오른쪽의 정렬된 부분과 정렬이 안 된 왼쪽 부분으로 나누어진다. 이러한 스캔 과정은 정렬되지 않은 부분에 대해 **더 이상 교환이 일어나지 않을 때까지** 수행된다. 그림에서는 6번의 스캔만에 교환이 발생하지 않는 상황이 되었고, 정렬이 완료되었다. 버블정렬 알고리즘은 다음과 같다.

``` Python
def bubble_sort(A):                                 # 버블 정렬
    n = len(A)
    for i in range(n-1, 0, -1):                     # 외부 루프 : n-1, n-2, ..., 2, 1
        bChanged = False
        for j in range(i):                          # 내부 루프 : 0, 1, ..., I-1
            if (A[j] > A[j + 1]):                   # 순서가 맞지 않으면
                A[j], A[j + 1] = A[j + 1], A[j]     # 교환! 코드에 유의할 것.
                bChanged = True                     # 교환이 발생했음
        
        if not bChanged:                            # 교환이 없으면
            break                                   # 종료
        printStep(A, n - i)                         # 중간과정 출력용 문장
```

실행 결과는 다음과 같다. 6번의 스캔만에 정렬이 완료되었다.

버블 정렬의 비교 횟수와 이동 횟수를 계산하여 보자. 버블 정렬의 비교 횟수는 최악의 경우 다음과 같다.

$$ \sum_{i=1}^{n-1} i = \frac {n (n-1)}{2} = O(n^2) $$

따라서 시간 복잡도는 $O(n^2)$이다. 어떤 경우가 최악일까? 최악의 경우는 입력 자료가 역순으로 정렬되어 있는 경우에 발생한다. 최선의 경우는 입력 자료가 이미 정렬이 되어 있는 경우로 1번의 스캔만에 알고리즘이 종료된다. 버블 정렬은 매우 단순하지만 효율적이지는 않다. 그러나 입력 데이터가 어느 정도 정렬되어 있는 경우에 효과적으로 사용될 수 있다.


### 7.3 정렬 응용 : 집합 다시보기

3장에서 리스트와 함께 집합을 공부했다. 집합은 원소의 중복을 허용하지 않으며 원소들 사이에 순서가 없다는 면에서 리스트와는 다르다. 3장에서 집합의 추상자료형을 정의하였고 파이썬의 리스트를 이용해 구현해보았다. 이제 집합을 다른 방법으로 구현해보자. 정렬의 개념을 사용하는 것이다.

이제 **집합의 원소들을 항상 정렬된 순으로 저장**하려고 한다. 이를 위한 코드는 기본적으로 3.6절에서 구현한 것과 동일하다. 변경되는 것은 멤버함수 몇 개다. 그렇다면 어떤 멤버함수가 변경되어야 할까? 당연히 삽입연산은 변경되어야 한다. 원소들이 정렬되어야 하므로 넣을 때마다 자기 자리를 먼저 찾아야하기 때문이다. 삭제연산은 동일하다. 중요한 것은 집합의 원소들이 정렬되어 있으면 **집합의 비교나 합집합, 차집합, 교집합 등을 훨씬 효율적으로 구현**할 수 있다는 것이다.


### 삽입 연산 : insert

집합에 원소를 삽입할 때 먼저 중복을 검사해야 한다. 중복되었으면 삽입하지 않아야하기 때문이다. 중복이 아니라면 삽입하는데, 이때는 반드시 삽입할 위치를 먼저 찾아야 한다. 리스트를 정렬된 상태로 유지해야 하기 때문이다. 이것은 삽입 정렬에서 하나의 항목을 정렬된 리스트에 끼워넣는 과정과 동일하다. 위치를 찾으면 리스트의 insert() 연산을 이용해 삽입하면 된다.

``` Python
def insert(self, elem):                     # 정렬된 상태를 유지하면서 elem을 삽입
    if elem in self.items:                  # 이미 있음
        return
    for idx in range(len(self.items)):      # loop : n번
        if elem < self.items[idx]:          # 삽입할 위치 idx를 찾음
            self.items.insert(idx, elem)    # 그 위치에 삽입
            return
    self.items.append(elem)                 # 맨 뒤에 삽입
```

리스트가 정렬되어 있든 그렇지 않든 삭제 연산은 바뀌는 것이 없다.


### 비교 연산 : ```__eq__```

두 집합이 같은 집합인지는 어떻게 비교할 수 있을까? 만약 정렬이 되어 있지 않은 상태에서 두 집합 A와 B가 같은 집합인지를 판단하려면 A의 모든 원소가 B에 있고, 반대로 B의 모든 원소가 A에 있는지를 검사해야 한다. 각 집합의 원소의 개수가 모두 $n$이라고 가정하면, 이 연산은 $n$의 제곱에 비례하는 비교가 필요하고 따라서 $O(n^2)$ 알고리즘이 된다. 

배열이 정렬되었다면 비교 연산은 다음과 같이 단순해진다.

* 두 집합의 원소의 개수가 같아야 같은 집합이 될 수 있다.
* 두 집합이 모두 정렬되어 있으므로 순서대로 같은 원소를 가져야 한다. 즉 가장 작은 원소부터 하나씩 끝까지 서로 비교하여 모두 같아야 같은 집합이다.

이를 구현한 코드는 다음과 같다.

``` Python
    def __eq__(self, setB):                         # 두 집합 self, setB가 같은 집합인가?
        if self.size() != setB.size():              # 원소의 개수가 같아야 함
            return False
        for idx in range(len(self.items)):          # loop : n번
            if self.items[idx] != setB.items[idx]:  # 원소별로 같은지 검사
                return False
        return True
```


```__eq___```는 파이썬에서 미리 정의된 특별한 메소드로 == 연산자에 대한 연산자 중복 함수이다. Set 클래스에서 이 메소드를 구현하면 두 Set 객체 A와 B를 A == B 와 같이 == 연산자를 이용해 비교할 수 있다. 산술 연산자(+, -, *, /)나 비교 연산자 등을 포함한 다양한 연산자 중복 메소드가 정의되어 있는데, 이들은 모두 __로 시작하여 __로 끝나는 이름을 갖는다. 2.11절을 복습하라.


이 알고리즘의 시간복잡도는? 한 집합의 원소의 개수만큼만 반복하면 같은 집합인지를 검사할 수 있다. 따라서 시간복잡도는 $O(n)$이다.


### 합집합 연산 : Union

합집합을 구하는 연산도 개선이 가능하다. 원소들이 크기순으로 정렬되어 있으면 1번의 스캔만으로 합집합을 구할 수 있다. 코드가 약간 복잡해 보이지만 핵심은 다음과 같다. 

* 두 집합의 원소들이 크기순으로 정렬되어 있으므로, 가장 작은 원소들부터 비교하여 더 작은 원소를 새로운 집합에 넣고 그 집합의 인덱스를 증가시킨다.
* 만약 두 집합의 현재 원소가 같으면 하나만을 새 집합에 넣으면 된다. 인덱스는 모두 증가시킨다.
* 한쪽 집합이 모두 처리되면 나머지 집합의 남은 모든 원소를 순서대로 새 집합에 넣는다.


``` Python
    def union(self, setB):                              # 집합 self와 집합 setB의 합집합
        newSet = Set()                                  # 반환할 합집합
        a = 0                                           # 집합 self의 원소에 대한 인덱스
        b = 0                                           # 집합 setB의 원소에 대한 인덱스
        while a < len(self.items) and b < len(setB.items):
            valueA = self.items[a]                      # 집합 self의 현재 원소
            valueB = self.items[b]                      # 집합 setB의 현재 원소
            if valueA < valueB:                         # self의 원소가 더 작으면
                newSet.items.append(valueA)             # 이 원소를 합집합에 추가
                a += 1                                  # self의 현재 원소 인덱스 증가
            elif valueA > valueB:                       # setB의 원소가 더 작으면
                newSet.items.append(valueB)             # 이 원소를 합집합에 추가
                b += 1                                  # setB의 현재 원소 인덱스 증가
            else:                                       # 중복되는 원소
                newSet.items.append(valueA)             # 하나만 추가
                a += 1                                  # self와 setB의 인덱스 모두 증가
                b += 1
        while a < len(self.items):                      # self에 남은 원소를 모두 추가
            newSet.items.append(self.items[a])
            a += 1
        while b < len(setB.items):                      # setB에 남은 원소를 모두 추가
            newSet.items.append(setB.items[b])
            b += 1
        return newSet                                   # 합집합 반환
```

이 연산의 시간복잡도는? 두 집합의 원소의 개수 합에 비례하는 비교가 필요하다. 만약 두 집합의 크기를 $n$이라고 한다면 이 연산의 시간복잡도는 $O(n)$이다. 이것은 3.6절에서 구현한 동일한 연산의 $O(n^2)$에 비해 엄청난 개선이다. 교집합이나 차집합도 같은 방법으로 구현할 수 있다. 실습문제 P7.3과 P7.4에 도전하라.

다음 표는 이들 연산에 대한 시간복잡도를 비교하고 있다. 결국, 정렬을 사용하면 삽입이 약간 번거롭기는 하지만 집합의 여러 연산들을 훨씬 효율적으로 처리할 수 있다.

[표 7.1] 정렬되지 않은 리스트와 정렬된 리스트로 구현한 집합에서의 복잡도 비교





## 7.4 탐색과 맵 구조

우리는 매일 인터넷에서 원하는 상품을 찾고, 특정한 단어나 문장이 들어있는 웹사이트를 검색한다. 이러한 모든 작업들이 모두 탐색이다. 효율적인 탐색을 위해서는 무엇이 필요할까? 미리 물건들을 일정한 규칙에 따라 잘 정리해 두어야 할 것이다. 자료를 효율적으로 탐색하기 위해 데이터를 잘 정리하는 방법을 살펴보자.





탐색은 **레코드(Record)**의 집합에서 원하는 레코드를 찾는 작업이다. 보통 이러한 레코드들의 집합을 **테이블(Table)**이라고 부른다. 레코드들은 서로를 구별하여 인식할 수 있는 키(Key)를 가지고 있는데, 이것을 **탐색키(Search Key)**라고 한다. 결국 탐색은 **테이블에서 원하는 탐색키를 가진 레코드를 찾는 작업**이다.

탐색에서는 테이블을 구성하는 방법에 따라 효율이 달라진다. **맵(Map)** 또는 **딕셔너리(Dictionary)**는 자료를 저장하고 탐색키를 이용해 원하는 자료를 빠르게 찾을 수 있도록 하는 **탐색을 위한 자료구조**를 말한다. 맵은 **엔트리(Entry)**라고 불리는 **키를 가진 레코드(Keyed Record)**의 집합이다. 엔트리는 2개의 필드를 가진다.

* **키(Key)** : 영어 단어나 사람의 이름과 같은 레코드를 구분할 수 있는 탐색키
* **값(Value)** : 영어 단어의 의미나 어떤 사람의 주소와 같은 탐색키와 관련된 값

결국 맵은 키-값의 쌍(key, value)으로 이루어진 엔트리의 집합이다. 파이썬은 내장 자료형으로 **딕셔너리**를 제공하는데, 이것은 **자료구조 맵을 구현한 하나의 예**이다. 다음은 딕셔너리의 사용 예시인데, 컬러 테이블에 몇 가지 색을 키(색상 이름)와 값(색상의 R, G, B 값)으로 저장하고 있다. 파이썬 딕셔너리는 2.6절을 복습하라.





이 장에서는 자료구조 맵이 어떻게 구성되어 있는지를 공부한다. 맵에는 어떤 연산이 있을까? 역시 가장 중요한 연산은 항목의 삽입과 삭제, 그리고 탐색 연산이다. 맵의 추상자료형을 정의해보자.

정의 7.1 Map ADT

* 데이터 : 키를 가진 레코드(엔트리)의 집합
* 연산
    - search(key) : 탐색키 key를 가진 레코드를 찾아 반환한다.
    - insert(entry) : 주어진 entry를 맵에 삽입한다.
    - delete(key) : 탐색키 key를 가진 레코드를 찾아 삭제한다.

맵에서는 유일한 탐색키를 사용하기도 하고, 동일한 탐색키를 허용하기도 한다. 예를 들어, 학생생활 기록부에서는 '학번'과 같은 유일한 탐색키를 반드시 사용해야 할 것이다. 그러나 영어사전에서는 철자가 동일한 여러 단어가 있으므로 탐색키의 중복을 허용해야 할 것이다. 맵을 효율적으로 구현하기 위해서는 이들 3가지 연산을 효율적으로 할 수 있는 자료구조를 사용해야 한다. 맵을 구현하는 여러가지 방법들을 살펴보자.

* 가장 간단한 방법은 엔트리들을 **리스트**에 저장하는 것이다. 이때, 엔트리들을 키 값에 따라 정렬하여 맵을 만들 수도 있고, 정렬하지 않고 맵을 만들수도 있다. 방법에 따라 연산들의 성능에 차이가 발생한다.
* 맵의 탐색 성능을 향상하고자 한다면 **이진탐색트리**를 사용할 수 있다. 이 방법은 9장에서 공부한다.
* 맵을 구현하는 가장 좋은 방법은 **해싱(Hashing)**이다. 이 장에서 공부한다.






## 7.5 간단한 탐색 알고리즘

### 순차 탐색(Sequential Search)


순차 탐색은 정렬되지 않은 테이블에서도 원하는 레코드를 찾을 수 있는 가장 단순하고 직관적인 방법으로, 테이블의 각 레코드를 처음부터 하나씩 순서대로 검사하여 원하는 레코드를 찾는다. 탐색을 위한 레코드들이 리스트에 저장되어 있다고 하자. 탐색 함수는 탐색 대상인 리스트 A와 탐색 키 Key, 그리고 리스트에서의 탐색 범위 low, high를 매개변수로 전달받는다. 리스트의 low 위치에서부터 탐색을 시작하여 탐색이 성공하면 항목의 위치를 반환한다. 만약 high까지도 원하는 레코드가 나타나지 않으면 None을 반환한다. 순차탐색 함수는 다음과 같다.

``` Python
def sequential_search(A, key, low, high):   # 순차탐색
    for i in range(low, high + 1):          # i : low, low + 1, ..., high
        if A[i].key == key:                 # 탐색 성공하면
            return i                        # 인덱스 반환
    return None                             # 탐색에 실패하면 None 반환
```

엔트리의 키 값으로 정수가 저장된다고 가정하고, 8과 2를 찾는 경우를 생각해보자. 8을 찾는 경우는 탐색에 성공하여 항목의 위치인 2를 반환하고, 2의 경우는 탐색에 실패하여 None을 반환한다.


[그림 7.7] 순차 탐색의 예 : 8과 2의 탐색



탐색의 성능을 살펴보자. 최선의 경우는 찾는 항목이 맨 앞에 있는 경우 (1번 비교)이고, 맨 뒤에 있거나 리스트에 없는 키를 찾는 경우 ($n$번 비교)가 최악이다. 모든 키가 탐색될 확률이 동일하다고 가정하면 평균 비교 횟수는 다음과 같다.

$$ (1 + 2 + 3 + ... + n) / n = (n + 1) / 2 $$

결국 순차탐색의 시간복잡도는 $O(n)$이다. 이 방법은 간단하고 구현하기 쉽지만 효율적이지는 않다. 그러나 테이블이 정렬되어 있지 않다면 순차 탐색 이외에 별다른 대안은 없다.


### 이진 탐색(Binary Search)

만약 테이블이 키 값을 기준으로 정렬되어 있다면 보다 개선된 탐색이 가능하다. **이진 탐색**은 테이블의 **중앙에 있는 값**을 조사하여 찾는 항목이 왼쪽에 있는지 오른쪽에 있는지를 판단한다. 찾는 항목이 왼쪽에 있다면 이제 오른쪽은 탐색할 필요가 없어지고, 따라서 매 단계마다 검색해야 할 항목의 수가 절반으로 줄어든다.

이진 탐색은 우리가 이미 일상생활에서 많이 사용하고 있다. 예를 들어, 사전에서 단어를 찾는 과정을 생각해보자. 사전을 펼쳐 찾고자 하는 단어가 현재 페이지보다 앞에 있는지 뒤에 있는지를 확인하고 단어가 있는 부분만을 다시 검색한다. 이것이 이진 탐색이다. 다음은 정렬된 배열에서 숫자 34를 이진 탐색으로 찾는 과정을 보여주고 있다.



[그림 7.8] 이진 탐색의 예 : 정렬된 배열에서 34를 탐색하는 경우



1. 최초의 탐색범위는 low = 0, high = 15이다. 중앙 위치 middle을 계산하고, 이 위치의 값(27)이 키 값(34)보다 작으므로 low ~ middle 사이에는 34가 없다. **이제 low는 middle + 1 = 18이 된다**. **탐색범위가 반으로 줄었다**.

2. 새로 계산한 middle 위치의 값(38)이 키 값보다 크다. 따라서 middle ~ high 사이에는 찾는 값이 없다. 이제 high가 middle - 1이 되고, 탐색범위는 다시 줄어든다.

3. middle 위치의 값(30)이 키 값보다 작다. 따라서 다시 low가 middle + 1이 된다.

4. middle 위치의 값(34)이 찾는 값이다. 탐색은 성공적으로 끝났다.


만약 찾는 값이 34가 아니라 33이었다면 어떻게 될까? 4단계에서 다시 high가 middle - 1이 된다. 그런데 문제가 발생한다. **low와 high가 역전**되는 것이다. 이것은 찾는 값이 없다는 것을 의미한다.

이진탐색 알고리즘을 구현해보자. 위의 알고리즘은 순환적이다. 따라서 순환 구조로 다음과 같이 구현할 수 있다.

``` Python
def binary_search(A, key, low, high):
    if (low <= higf):                               # 항목들이 남아 있으면 (종료조건)
        middle = (low + high) // 2                  # 정수 나눗셈 //에 주의할 것
        if key == A[middle].key:                    # 탐색 성공
            return middle
        elif key < A[middle].key:                   # 왼쪽 부분 리스트 탐색
            return binary_search(A, key, low, middle - 1)
        else:                                       # 오른쪽 부분 리스트 탐색
            return binary_search(A, key, middle + 1, high)
    return None                                     # 탐색 실패
```

middle은 배열의 **인덱스**이므로 정수가 되어야 한다. 파이썬에서는 두 가지 나눗셈 연산자 /와 //를 제공하는데, **/ 연산의 결과는 실수(float)** 객체이고, **// 연산의 결과는 정수(int)**라는 것을 명심하라.


알고리즘은 순환적으로 기술되었지만 이를 반복 구조로도 구현할 수 있다. 이진 탐색을 반복 구조로 구현한 코드는 다음과 같다. 물론 효율성을 위해서는 반복 구조가 더 유리할 것이다.

``` Python
def binary_search_iter(A, key, low, high):
    while (low <= high):                # 항목들이 남아 있으면 (종료조건)
        middle = (low + high) // 2
        if key == A[middle].key:        # 탐색 성공
            return middle
        elif key > A[middle].key:       # key가 middle의 값보다 크면
            low = middle + 1            # middle + 1 ~ high 사이 검색
        else:                           # key가 middle의 값보다 작으면
            high = middle - 1           # low ~ middle - 1 사이 검색
    return None                         # 탐색 실패
```

이진 탐색은 각 단계에서 탐색 범위가 반으로 줄어든다. 탐색 범위가 1이 될 때의 탐색 횟수를 $k$라 하면, $n / 2^k = 1$이 된다. 즉, $k = log_2 n$이므로 이진탐색의 시간복잡도는 $O(log_2 n)$이다. 만약 10억 명이 정렬된 배열에서 순차 탐색으로 특정한 이름을 찾는다면 평균 5억번의 비교가 있어야 되지만, 이진 탐색을 이용하면 단지 30여 번의 비교만으로 탐색이 완료된다! 이것은 엄청난 차이이다.

이진 탐색은 매우 효율적인 탐색 방법이지만 탐색하기 전에 반드시 배열이 정렬되어 있어야 한다는 전제조건이 있다. 따라서 이진 탐색은 **데이터의 삽입이나 삭제가 빈번한 응용에는 적합하지 않다**.


### 보간 탐색(Interpolation Search)

보간탐색은 이진탐색의 일종으로 우리가 사전에서 단어를 찾을 때와 같이 **탐색키가 존재할 위치를 예측하여 탐색**하는 방법이다. 예를 들어, 'ㅎ'으로 시작하는 단어는 사전의 뒷부분에서 찾고 'ㄱ'으로 시작하는 단어는 사전의 앞부분에서 찾는 것과 같은 원리이다.

이진 탐색에서 탐색 위치 middle은 (low + high) / 2로 항상 리스트를 반으로 분할했지만, 보간 탐색에서는 찾고자 하는 키 값과 현재의 low, high 위치의 값을 고려하여 다음과 같이 다음 탐색위치를 결정한다.

$$ 탐색위치 = low + (high - low) * \frac {k - A[low]}{A[high] - A[low]} $$

여기에서 $k$는 찾고자 하는 키 값을, low와 high는 각각 탐색할 범위의 최소, 최대 인덱스를 나타낸다. 이 식은 다음 그림과 같이 **탐색 값과 위치는 비례한다는 가정**에서 탐색 위치를 결정할 때 찾고자 하는 키 값이 있는 곳에 근접하도록 가중치를 주는 방법이다.


[그림 7.9] 보간 탐색은 찾는 값과 위치가 비례한다고 가정한다.




코드는 이진탐색 함수에서 middle 계산 코드만 다음과 같이 수정하면 된다.

``` Python
middle = int(low + (high - low) * (key - A[low].key) / (A[high].key - A[low].key))
```


위치의 비율을 계산하기 위해 실수 계산이 사용되지만 마지막에 인덱스로 변경할 때에는 반드시 정수로 변환해야 하는 것에 유의하라. 보간 탐색은 이진 탐색과 같은 $O(log_2 n)$의 시간복잡도를 갖지만 많은 데이터가 비교적 균등하게 분포되어 있는 자료의 경우 훨씬 효율적인 방법이다.




## 7.6 고급 탐색 구조 : 해싱

### 해싱이란?

생각하기는 싫지만 아파트 단지에서 모든 택배나 우편물을 단 하나의 우편물 함에 모아둔다면 어떻게 될까? 자신의 집으로 배달된 것을 찾기 위해 수많은 우편물들을 뒤져야 할 것이다. 다행히 대부분의 아파트에는 각 호실별로 우편함이 있어 우편물이 분리되어 저장되고, 우리는 세대별 우편물을 고생하지 않고 금방 찾아갈 수 있다. 물론 이를 위해서는 세대별로 우편함을 만들어야 하므로 공간과 비용이 필요하다.






해싱은 세대별 우편함과 비슷하다. 지금까지의 탐색 방법들은 탐색키와 각 레코드의 키 값을 **비교**하여 원하는 항목을 찾았는데, 해싱은 완전히 다른 방법을 사용한다. 비교하는 것이 아니라 **키 값에 산술적인 연산**을 적용하여 레코드가 저장되어야 할 위치를 직접 계산하는 것이다. 따라서 탐색은 테이블에 있는 레코드를 하나씩 비교하는 것이 아니라 탐색키로부터 레코드가 있어야 할 위치를 계산하고, 그 위치에 레코드가 있는지를 확인만 하면 된다. 이것은 우리집 우편함에 온 편지가 있는지를 확인하는 것과 동일하다. 해싱에서 키 값으로부터 레코드가 저장될 위치를 계산하는 함수를 **해시 함수(Hash Function)**라 한다. 또한 해시 함수에 의해 계산된 위치에 레코드를 저장한 테이블을 **해시 테이블(Hash Table)**이라 한다.

예를 들어, 탐색키가 모두 1 ~ 1000 사이의 정수라고 가정하자. 가장 빠르게 탐색할 수 있는 방법은 1000개의 항목을 가지는 배열(우편함)을 만드는 것이다. 자료의 삽입과 탐색은 **탐색키를 인덱스**로 생각하고 그 위치에 저장하거나 읽어오면 된다. 이 경우의 해시 함수는 $h(key) = key$가 된다. 이들 연산은 명백하게 $O(1)$이다. 이것이 해싱의 기본 아이디어이다. 빠르게 탐색할 수는 있지만 이를 위해 1000개의 우편함이 필요함에 유의하라.

만약 **탐색키가 문자열이거나 실수, 또는 굉장히 큰 정수**라면 문제가 발생한다. 이것은 아파트에 세대수가 너무 많아 세대별 우편함을 만들 공간이 부족한 상황이다. 메모리가 부족하면 보다 작은 배열을 사용해야 하고, 탐색키를 더 이상 직접 배열의 인덱스로 사용할 수 없다. 대신에 탐색키를 작은 정수로 대응시키는 해시 함수가 필요하다. **해시 함수**는 탐색키를 입력받아 **해시 주소(Hash Address)**를 계산하는데, 삽입이나 삭제, 탐색 연산은 모두 이 주소에서 이루어진다.



### 해싱과 오버플로우

해시 테이블은 $M$개의 **버킷(Bucket)**으로 이루어지는 테이블이고, 하나의 버킷은 여러개의 슬롯(Slot)을 가지는데, 하나의 슬롯에는 하나의 레코드가 저장된다. 단순화를 위해 슬롯이 하나라고 가정하자.

키 값 $key$가 입력되면 해시 함수로 연산한 결과 $h(key)$가 **해시 주소**가 되고, 이를 인덱스로 사용하여 항목에 접근한다. 그런데 버킷이 충분하지 않으면 경우에 따라 **서로 다른 키가 해시함수에 의해 같은 주소로 계산되는 상황**이 발생한다. 이것을 **충돌(Collision)**이라고 하고, 충돌을 일으키는 키들을 **동의어(Synonym)**라 한다. 다음은 해싱의 예를 보여주는데, 각 탐색키에 대한 해시 함수의 계산 결과는 다음과 같다고 가정하자.

$$ h(홍길동) => 3, h(이순신) => 2, h(장영실) => 5, h(임꺽정) => 3 $$


[그림 7.10] 해싱의 구조



'홍길동'과 '임꺽정'이 같은 주소로 계산되어 충돌이 발생하였다. 즉, '홍길동'과 '임꺽정'은 동의어이다. 충돌이 발생하면 어떻게 될까? 만약 버킷에 여러개의 슬롯이 있다면 서로 다른 슬롯에 저장하면 된다. 그러나 충돌이 슬롯 수보다 더 많이 발생할 수도 있다. 이러한 상황을 **오버플로우(Overflow)**라 하는데, 해당 버킷에 더 이상 항목을 저장할 수 없게 된다. 따라서 해싱에서는 오버플로우를 반드시 해결해야 한다.

**이상적인 해싱**은 충돌이 절대 일어나지 않는 경우로, 해시 테이블의 크기를 충분히 크게 하면 가능하지만 메모리가 지나치게 많이 필요하다. 따라서 실제의 해싱에서는 테이블의 크기를 적절히 줄이고, 해시 함수를 이용해 주소를 계산한다. 이러한 **실제의 해싱**에서는 충돌과 오버플로우가 빈번하게 발생하므로 시간복잡도는 이상적인 경우의 $O(1)$보다는 떨어지게 된다.


### 선형 조사에 의한 오버플로우 처리

선형 조사법(Linear Probing)은 해싱 함수로 계산된 버킷에 빈 슬롯이 없으면 그 다음 버킷에서 빈 슬롯이 있는지를 찾는 방법이다. 이때 비어있는 공간을 찾는 것을 조사(probing)라고 한다. 선형 조사법은 해시 테이블의 $k$번째 위치인 $ht[k]$에서 충돌이 발생했다면 다음 위치인 $ht[k+1]$부터 순서대로 비어 있는지를 살피고(조사), 빈 공간이 있으면 저장한다. 이 과정은 비어있는 공간이 나올 때까지 계속된다. 만약 테이블의 끝에 도달하면 다시 테이블의 처음으로 간다. 만약 조사 과정에서 처음 충돌이 발생한 곳으로 다시 돌아왔다면 테이블이 가득 찬 상태이다.




#### 삽입 연산

선형 조사법으로 해시 테이블에 키 값이 각각 45, 27, 88, 9, 71, 60, 46, 38, 24 인 레코드를 저장해보자. 테이블의 크기가 $M = 13$이고, 해시 함수는 키 값을 테이블의 크기로 나눈 나머지 연산 $h(k) = k (나머지연산) M$을 이용한다면 각 키에 대한 해시 주소는 다음과 같이 계산된다.






이제 레코드들을 선형 조사법으로 저장해보자.

1. 45, 27, 88, 9 까지의 삽입은 문제없다. 해당 주소가 비어있기 때문이다.

2. 71의 삽입에서 충돌이 발생한다. 선형 조사법에서는 다음의 비어있는 공간을 찾는다. 따라서 7 위치에 71을 저장한다.

3. 60의 삽입은 문제없다. 8 위치에 저장하면 된다.

4. 46의 삽입에서 다시 충돌이 발생한다. 비어있는 공간을 찾아 여러번 움직여야 11 위치를 찾을 수 있고, 여기에 46을 저장할 수 있다.




5. 38은 충돌없이 12 위치에 저장된다. 마지막으로 24는 충돌이 발생한다. 그런데 뒤쪽으로 남은 버킷이 없다. 이 경우 다시 처음으로 돌아가 검사한다.



그림을 보면 한번 충돌이 발생한 위치에서 항목들이 집중되는 현상을 볼 수 있는데, 이것을 **군집화(Clustering)** 현상이라고 한다. 선형 조사법은 간단하지만 오버플로우가 자주 발생하면 군집화 현상에 따라 탐색의 효율이 크게 저하될 수 있다.


#### 탐색 연산

탐색은 삽입과 비슷한 과정을 거친다. 탐색키가 입력되면 해시주소를 계산하고, 해당 주소에 같은 키의 레코드가 있으면 탐색은 성공이다. 만약에 없으면 어떻게 될까? 삽입과 같은 방법으로 계속 다음 버킷을 검사해야 한다. 이 과정은 해당 키의 **레코드를 찾거나, 레코드가 없는 버킷을 만나거나 모든 버킷을 다 검사**할 때까지 진행된다. 예를 들어, 다음과 같이 46은 결국 탐색에 성공하지만 39의 경우 다음 버킷은 27이고 다음 버킷이 비었으므로 탐색은 실패로 끝난다.


[그림 7.11] 선형조사법으로 구현된 해싱에서의 탐색과정 예 (46과 39 탐색)


#### 삭제 연산

선형 조사법에서 항목이 삭제되면 탐색이 불가능해질 수가 있다. 앞의 예에서 60을 먼저 삭제했다고 하자. 이 상태에서 46을 탐색하려고 한다. 문제는 60이 있던 위치가 이제는 비어있기 때문에 46의 위치로 갈 수가 없다. 이 문제를 어떻게 해결할 수 있을까? **빈 버킷을 2가지로 분류**해야 한다. 즉, 한 번도 사용하지 않은 것과, 사용되었다가 삭제되어 현재 비어있는 버킷으로 나누어야 한다. 탐색과정은 1번도 사용이 안 된 버킷을 만나야만 중단되도록 한다.


[그림 7.12] 선형조사로 구현된 해싱에서의 삭제 문제 (빈 버킷을 2가지로 분류해야 함)



#### 이차 조사법(Quadratic Probing)

군집화 문제를 완화시키기 위한 방법으로 충돌이 발생하면 다음에 조사할 위치를 다음 식에 의해 결정하는 방법이다. 

$$ (h(k) + i * i) 나머지연산 M for i = 0, 1, ..., M-1 $$

따라서 조사되는 위치는 $h(k)$, $h(k)+1$, $h(k)+4$, $h(k)+9$와 같이 움직인다. 물론 계산된 주소에 나머지 연산(%M)을 적용해야 한다. 이 방법은 군집화 현상을 완화시킬 수 있는데, 물론 2차 집중 문제를 일으킬 수는 있지만 1차 집중처럼 심각한 것은 아니다. 2차 집중의 이유는 동일한 위치로 사상되는 여러 탐색키들이 같은 순서에 의하여 빈 버킷을 조사하기 때문이다. 이것은 다음에 소개할 이중 해싱법으로 해결할 수 있다.



#### 이중 해싱법(Double Hashing)

**재해싱(Rehashing)**이라고도 불리는 이 방법은 충돌이 발생해 저장할 다음 위치를 결정할 때, 원래 해시 함수와 다른 별개의 해시 함수를 이용하는 방법이다. 선형 조사법과 이차 조사법은 충돌이 발생하면 해시 함수 값에 따라 각각 1 또는 $j^2$을 더해서 다음 위치를 얻는다. 따라서 해시 함수 값이 같으면 다음 위치도 같게 된다. 이중 해싱법은 해시 함수 값이 같더라도 탐색키가 다르면 서로 다른 조사 순서를 갖도록 하여 2차 집중을 완화할 수 있다.


### 체이닝(Chaining)에 의한 오버플로우 처리

체이닝은 하나의 버킷에 여러개의 레코드를 저장할 수 있도록 하는 방법으로, 버킷은 보통 연결 리스트로 구성된다. 체이닝을 이용해 크기가 7인 해시 테이블에 $h(k) = k (나머지연산) 7$의 해시 함수를 이용하여 8, 1, 9, 6, 13 을 삽입하는 과정을 살펴보자.

1. 8 저장 : h(8) = 8 % 7 = 1 --> 저장
1. 1 저장 : h(1) = 1 % 7 = 1 --> 충돌 --> 새로운 노드 생성 및 저장
1. 9 저장 : h(9) = 9 % 7 = 2 --> 저장
1. 6 저장 : h(6) = 6 % 7 = 6 --> 저장
1. 13 저장 : h(13) = 13 % 7 = 6 --> 충돌 --> 새로운 노드 생성 및 저장


[그림 7.13] 체이닝으로 구현된 해싱의 구조




**체이닝**을 **연결 리스트**로 구현한다면 삽입하는 노드를 맨 끝이 아니라 **맨 앞에 추가**하는 것이 훨씬 효율적이다. 따라서 이 경우 1번 버킷에는 1 -> 8의 순서로, 6번 버킷에는 13 -> 6의 순서로 저장된다. 만약 **파이썬의 리스트**를 이용한다면 append() 연산을 이용해 리스트의 **맨 뒤에 추가**하는 것이 더 효율적일 것이다.


체이닝에서 항목을 탐색하거나 삽입하고자 하면 키 값의 버킷에 해당하는 연결 리스트에서 독립적으로 탐색이나 삽입이 이루어진다. 체이닝은 해시 테이블을 연결 리스트로 구성하므로 필요한 만큼의 메모리만 사용하게 되어 공간적 사용 효율이 매우 우수하다. 또한 오버플로우가 발생할 경우에도 해당 버킷에 할당된 연결 리스트만 처리하게 되므로 수행 시간 면에서도 효율적이다.


### 해시 함수

좋은 해시 함수는 충돌이 적어야 하고, 주소가 테이블에서 고르게 분포되어야 하며, 계산이 빨라야 한다. 예를 들어, 영어단어의 첫 문자만을 취하여 해시 주소를 만드는 것은 좋지 않다. 왜냐하면 'x'나 'z'로 시작하는 단어는 별로 없으므로 해시 테이블을 고르게 사용하지 못한다. 먼저 탐색키가 정수라고 가정하고 해시 함수들을 살펴보자.


#### 제산 함수

가장 일반적인 방법이 앞에서 사용한 것과 같이 나머지 연산 % (modular)을 이용하는 것이다. 테이블의 크기가 $M$일 때 탐색키 $k$에 대하여 해시함수는 다음과 같다.

$$ h(k) = h mod M $$

이때, 가능하면 해시 테이블의 크기 $M$은 소수(Prime Number)를 선택한다. 즉, 1과 자기 자신만을 약수로 가지는 수라면 $k mod M$이 0에서 M-1을 골고루 사용하는 값을 만들어낼 수 있기 때문이다.


#### 폴딩 함수

탐색키가 해시 테이블의 크기보다 더 큰 정수일 경우에 사용된다. 예를 들어 탐색키가 32비트이고 해시 테이블의 인덱스가 16비트라고 생각해보자. 만약 탐색키의 일부만을 (예를 들면 뒤쪽 16비트) 사용한다면 많은 충돌이 발생할 수 있다. 보다 좋은 방법은 탐색키를 몇 개의 부분으로 나누어 이를 더하거나 비트별 XOR과 같은 부울 연산을 이용하는 것인데, 이를 **폴딩(Folding)**이라고 한다. 


[그림 7.14] 탐색키에 대한 다양한 폴딩의 예 : 이동폴딩과 경계폴딩



폴딩 함수에서 탐색키를 나누고 더하는 방법에는 **이동 폴딩(Shift Folding)**과 **경계 폴딩(Boundary Folding)**이 대표적이다. 이동 폴딩은 탐색키를 여러 부분으로 나눈 값들을 더하고, 경계 폴딩은 이웃한 부분을 거꾸로 더해 해시 주소를 얻는다.



#### 중간 제곱 함수

탐색키를 제곱한 다음, 중간의 몇 비트를 취해서 해시 주소를 생성하는 방법이다. 제곱한 값의 중간 비트들은 대개 탐색키의 모든 자리의 숫자들과 관련이 있다. 따라서 두 키 값에서 몇 개의 자리가 같더라도 서로 다른 해싱 주소를 갖게 된다. 탐색키를 제곱한 값의 중간 비트들은 보통 비교적 고르게 분산된다.


#### 비트 추출 방법

해시 테이블의 크기가 $M = 2^k$일 때 탐색키를 이진수로 간주하여 임의의 위치의 $k$개의 비트를 해시 주소로 사용하는 것이다. 이 방법은 간단하지만 탐색키의 일부 정보만을 사용하므로 해시 주소의 집중 현상이 일어날 가능성이 많다.


#### 숫자 분석 방법

이 방법은 숫자로 구성된 키에서 각 위치마다 수의 특징을 미리 알고 있을 때 유용하다. 키의 각 위치에 있는 숫자 중에서 편중되지 않는 수들을 해시 테이블의 크기에 적합한 만큼 조합하여 해시 주소로 사용하는 방법이다. 예를 들면, 학생의 학번이 201912345와 같이 부여되면 입학년도를 의미하는 앞의 4 자릿수는 편중되므로 사용하지 않고 나머지 자리의 수들을 조합하여 해시 주소로 사용한다.



#### 탐색키가 문자열인 경우

탐색키가 문자열인 경우는 보통 각 문자에 정수를 대응시켜 바꾸게 된다. 예를 들면, 'a'부터 'z'에 1부터 26을 할당할 수도 있고, 각 문자의 아스키 코드나 유니코드 값을 그대로 이용할 수 있다. 가능하면 문자열 안의 모든 문자를 골고루 사용하는 것이 좋을 것이다. 다음은 문자열 Key를 받아 각 문자의 코드 값을 모두 더하고 이를 테이블 크기 M으로 나머지 연산하여 주소를 계산하는 해시함수의 예이다.

``` Python
def hashFn(key):
    sum = 0
    for c in key:           # 문자열의 모든 문자에 대해
        sum = sum + ord(c)  # 그 문자의 아스키 코드 값을 sum에 더함
    return sum % M
```

파이썬에서 ord()는 문자를 아스키 코드 값으로 바꿔주는 함수이다. 만약 'a'부터 'z'까지를 0 ~ 25로 할당하려면 ord(c) - ord('a')를 사용하면 된다.


### 탐색 방법들의 성능 비교

해싱의 시간복잡도는 $O(1)$이다. 그러나 이것은 충돌이 전혀 일어나지 않는 상황에서만 가능하다. 따라서 실제 해싱의 탐색 연산은 $O(1)$보다는 느리다. 해싱의 성능을 분석하기 위해 해시 테이블이 얼마나 채워져 있는지를 나타내는 **적재밀도(Loading Density)** 또는 **적재 비율(Loading Factor)**을 다음과 같이 정의한다.

$$ \alpha = \frac {저장된 항목의 개수}{해싱 테이블의 버킷의 개수} = \frac {n}{M} $$

$\alpha$가 0이면 해시 테이블은 비어있다. $\alpha$의 최대값은 충돌 해결 방법에 따라 달라진다. 선형 조사법에서는 테이블이 가득 차면 모든 버킷에 하나의 항목이 저장되므로 1이 된다. 체인법에서는 저장할 수 있는 항목의 수가 해시 테이블의 크기를 넘어설 수 있기 때문에 $\alpha$는 최대값을 가지지 않는다.

다음 표는 여러가지 탐색 방법들의 시간복잡도를 보여주고 있다. 가장 단순한 순차 탐색은 탐색 시간이 가장 많이 걸린다. 테이블의 정렬이 필요한 **이진탐색**은 효율적이지만 레코드의 삽입과 삭제에 대한 처리가 복잡하다. 이에 비해 9장에서 공부할 **이진탐색트리**는 탐색의 시간복잡도는 같지만 삽입이나 삭제가 쉽다.


[표 7.2] 다양한 탐색 방법의 성능 비교



이상적인 경우 **해싱**이 가장 효율적인 방법이다. 물론 단점도 있다. 해싱은 그야말로 순서가 없다. 따라서 정렬된 배열이나 이진탐색트리와 같이 어떤 항목의 이전 항목이나 다음 항목을 쉽게 찾을 수 없다. 또한 해시 테이블의 크기를 결정하는 것이 불명확하다. 또한 최악의 경우, 즉 모든 키가 하나의 버킷으로 집중되면 시간복잡도는 $O(n)$이 된다.



## 7.7 맵의 응용 : 나의 단어장

(오늘은 여기까지!! 내일부터 다시 시작!!)



























