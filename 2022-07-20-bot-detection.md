

* Date : 2022-07-18
* Last Modified At : 2022-07-18






넥슨, 2017년, 인텔리전스 랩 설립

* 인텔리전스 랩은 넥슨의 모든 게임에 적용할 수 있는 표준화된 형식의 로그(기록) 데이터를 자동으로 저장/분석함
* 이를 기반으로 어뷰징, 불법 프로그램 등의 이변을 탐지
* 라이브 봇 디텍션(Live Bot Detection, LBD) : 이용자의 게임 행위 데이터를 기계학습으로 분석, 이용자가 얼마나 기계적인 행동 또는 반복 플레이를 하는지 탐지
* 오탐지율 1% 미만이라고 한다.
* 텍스트 탐지 시스템 '초코' : 욕설, 도박, 광고 차단 / 새로운 타입의 욕설, 변형욕설, 광고용어를 손쉽게 습득하고 탐지
* 넷마블의 콜럼버스 프로젝트 : 한달 접속자 수 6800만(넷마블), 수집되는 게임 로그를 AI 기술에 활용

<img src = 'http://itimg.chosun.com/sitedata/image/202001/03/2020010301793_4.jpg'>

기계학습 기법으로 게임 내 비정상 이용자를 탐지하면, 기존 방식과 비교해 2~10배 정도 좋은 효과를 볼 수 있다. by 넷마블







## 어뷰징이란?

기획적으로 의도하지 않은 방식으로 게임 정보를 대량 획득하거나 도움을 주는 행위

ex) 서비스 구현상의 헛점을 이용한 플레이, 해킹 툴을 사용한 비정상 플레이, 채팅창 도배 광고


## 동기?

유저의 신고, GM 모니터링, 단순 패턴찾기로는 어뷰징 검출 한계
사람의 개입이 최소화된 탐지 시스템 만들기! -> 내가 했던 연구에서 사람의 지식개입을 최소화하며 자동 특성 분석을 했던 것과 유사하다.


## 프레이밍험 연구(1948)

심장병의 원인을 찾기 위한 최초의 대규모 역학 연구
5000명의 성별, 연령, 병력, 혈압 등을 조사
펀치 카드(Punch Card)에 데이터를 저장
10년 뒤 IBB의 대형 계산기로 겨우 분석되었다고 한다.

기본적으로 통계학은 열악한 상황에서 발전하였다.
* 데이터의 수집도 어렵고, 있어도 계산하기 힘들기 때문에, 통계학자들은 데이터/계산을 효율적으로 줄이는 연구를 많이했음

오늘날 ML로 인해 자동 특성 분석이 되므로 통계학의 비중이 낮아졌다고 볼 수도 있지만,

기본적으로 통계학은 열악한 환경에서 만들어졌기에, 적은 데이터에서도 가치를 발견할 수 있고, 또한 기본적인 통계 지식은 개발, 기획, 서비스 등에 큰 도움이 된다.


## 오늘날 빅데이터의 시대

컴퓨터와 인터넷 -> 데이터 수집, 분석 용이
통계적 이론을 통한 근사화의 중요도가 낮아짐 -> ml, dl 모델이 대체
다양한 데이터 분석법과 툴의 발전

## 일반적인 데이터 분석 흐름

1. 도메인과 데이터의 구조 파악
2. 데이터 수집
3. 분석 모델 설계
4. 평가 후 적용

Hadoop : 대용량 로그에서 기계학습을 위한 피처 생성, 나는 이런 전문적인 데이터관련 툴을 그 동안 쓸 일이 없었는데, 앞으로는 이쪽도 공부해봐야 할듯
 파이썬 : 다양한 패키지를 기반으로 거의 모든 일을 다할수 있다.



# 탐색적 데이터 분석 (Exploratory Data Analysis, EDA)

데이터에 숨어있는 정보를 다양한 각도로 요약하고, 시각화해보며 패턴을 추론하는 과정
처음 데이터를 접하면 데이터에 대해 익숙하지 않기 때문에, 데이터와 친해지는 과정이 필요. 
도메인 지식이 있으면 더 좋다.


## 사례1. 간단한 통계 아이디어로 스팸(광고) 검출

게임의 채팅창이 광고글/도배로 가득한 상황에서
빠른 제제가 필요한데, 기계학습을 하기에는 시간도 데이터도 부족한 상황이면?

일반적으로 온라인에서의 채팅 메시지 길이 분포는 로그 정규분포를 따른다고 알려져 있음.
NPS Chat Corpus의 메시지 길이 분포를 보면 다음과 같다.

반면, 게임 내 채팅 메시지 길이 분포는, 온라인 채팅과 비슷하지만 좀더 두꺼운 경향,
특정한 길이의 메시지가 지나치게 많이 반복되면? --> 분포상에서 특이한 점으로 보임. --> 스팸 판정

자연어처리나 기계학습같은 고급 접근보다 간단한 통계적 아이디어로 시도하는 것이 의외로 잘 먹히는 경우가 많다.
- 일반 메시지 : 길이 다양, 빈도 적음
- 스팸 : 길이 다양하지 않음, 빈도 높음
즉, 빈도가 높고 길이가 다양하지 않으면 스팸이라고 룰을 세울수있음


## 기계학습의 장점

적은 노력으로 괜찮은 결과물, 다양한 문제에 대한 일반적 솔루션 구현, 다수의 특성을 동시 고려가능, 데이터 변동에 강함(강건성, robustness)

어뷰징 검출은 분류에 속함, 이진분류


## 알고리즘들

기본 : Linear/Logistic regression, 결정트리
고급 : 랜덤포레스트, SVM, 인공신경망

인공신경망 : 딥러닝, 모든문제에 적합하지 않음, 보통 고급 알고리즘은 더 복잡한 모델 학습이 가능하지만 항상 좋다는 보장은 없음.
학습 결과를 사람의 추상적 의미수준에서 이해하기에는 기본적인 ML 모델이 더 좋다. 실제로 학회연구의 상당부분은 DL이아니라 ML 모델을 적극 활용함

## 평가는 어떻게 하는가?

정확도(Accuracy) : 유저 100명 중 2명 있는 어뷰저를 검출하려고 할 때, 모델이 무조건 정상유저로 판단한다고 하면 정확도는 98%로 나옴.
                   즉, 클래스 불균형이 극단적인 상황에서 정확도 메트릭만으로는 모델의 성능을 제대로 표현할 수 없음.

그래서 나온것이? 재현율(Recall), 정밀도(Precision) 등..

재현율 : 전체 어뷰저 중 얼마나 찾았는가?
정밀도 : 찾은 것 중 몇개가 진짜 어뷰저인가?


## 사례2. 기계학습으로 어뷰징 검출

게임에서 각종 해킹 툴을 이용하여 어뷰징(파밍) 플레이를 하는 상황, 봇의 특성이 여러가지라면 판정 어려움 -> ML 도입

학습방식 : 굳이 딥러닝을 할 필요는 없다. 작은 모델이 오히려 다루기 편함

1. 정형 데이터로 된 로그를 받을 경우, 먼저 떠올릴수 있는 것은 dECISION TREE로 분류하기

로그 데이터 확인, 데이터의 구조, 의미 파악, FEATURE 추출


실제 분석에서는 **로그를 체계적으로 모으고, 가공하는데 대부분의 시간이 걸릴것 같다.** 
학습 자체는 그렇게 오래 걸리지 않는다.
적절히 분류된 로그 데이터가 저장할 대규모 서버등이 필요할 것이다. 클라우드 스토리지(s3)라는게 추천된다?

# 특성 엔지니어링

feature는 학습 대상의 특징을 설명해주는 값,

예를 들어, 집값 예측하는 경우 : 집의 크기, 방향, 환경, 편의시설 등이 집값에 영향을 주는 특성임

* 특성 엔지니어링이란, 데이터에서 피처를 찾고 생성하는 작업
* 하둡이라는 서비스로 피처를 생성했다고 하는데, 이 부분이 애매하다. 자동화된 피처생성인지? 도메인 지식을 활용하였는지?
* 다행히 하둡은 big 데이터가 아니면 필수는 아니라고 함.
* etl이 뭐지?
* 그러나 비정형/대용량 데이터에서 빈번하게 특성 엔지니어링을 한다면 하둡 등이 좋다고 한다.
* 클라우드 서비스에서 하둡 서비스 제공한다고 한다 ex) AWS의 EMR(Elastic Map Reduce)
* 하둡에서 쓸 경우, 로그를 가공해야 된다고 한다. 작은 파일(100 mb)가 많으면 취약해서, 작은 파일들을 병합, 정렬, 압축할 필요 있음

어뷰징에서는 GM이 제제하는 근거(어뷰징 피처) + 제제된 캐릭터 리스트가 필요할 것

피처 생성의 팁? 로그에서 캐릭터(NEWid) 기준으로 구했다고 한다. 정교한 피처보다 다양한 피처가 중요? 복합적으로 판단할 것이므로,
초기에는 짧은 시간에 대한 로그데이터를, 나중에 안정화되면 오랜 시간에 대한 로그 데이터를 수집

* 초기 피처 : 로그인 수, 플레이 시간(로그아웃이 불분명한 경우가 많다?), 아이템/머니 습득 수, 퀘스트 종료 수, NPC/PC간 전투 수 등
* 특성 형태 : 실수형/카테고리형/Boolean 형 -> 실수형으로 통일하는 것이 바람직, boolean은 True/false , 0, 1로
* 카테고리 타입이면 : onehot encoding 시도 가능


# 학습

기계학습 자체는 가벼운 편에 속하는 학습.

그러나 하이퍼파라미터 최적화는 무거운 편. (Ray tune과 같은 분산학습 시스템을 활용하면 좋을듯, 물론 sklearn에서는 필요없어보이기도 한다.)

decision tree는 피처의 정규화가 필요업성서 편리

초기 결과는 평균정확도 80%가 나왔다고 한다. 나도 비슷하게 나옴. 대충해도 이정도는 나오지만, 실제로 confusion matrix로 확인하면, 일반유저를 정상유저로 판단하는 비중이 꽤 높음. 이 모델을 장기적으로 활용하면 정상유저들이 정지먹고 사용자 수가 감소하는 사태가 날것이 뻦ㄴ함.

결국, 어뷰징 제제의 근거로 ML을 쓰기에는 부족

--> 교차검증(CV, Cross-validation) + Gridsearch로 최적 하이퍼파라미터를 찾음.
--> 약간 성능이 올라가기는 했지만, 드라마틱하게 올라가지는 않음.
--> 모델이 내부적으로 어떤 특성을 중요하게 여기는지 보기 위해 feature importance를 정렬하여 시각화해봄
--> 참고로 다른 사람들의 관련자료에서는 로그 데이터의 세부특성을 명확하게 알 수 있는 특성이름으로 되어 있는데, 내가 받은 데이터는 그렇지 못했으므로
--> 일부 특성에 대해서만 짐작할 수밖에 없었다.
--> 그래도 어느정도 말이 되는 결과들이 나왔음.  (나중에 후술)

* 학습된 모델이 판정하는 기준을 어느정도 알 수 있었다. 그러나 단일 DT는 과적합되기 쉬운 단점이 있음.

* 다른 사람들의 사례를 보면, 모델 성능이 정체된 상태에서 추가적인 피처를 추가했다고 한다.
- 동시에 얻은 아이템/머니수
- 맵 반복 횟수
- 특정 클래스만 선택
- 캐릭터 이름의 랜덤 생성 여부
- 움직이지 않고 얻은 아이템 수
- 난해해보이는 것들도 특성으로 만들 수 있는것이 노하우라고 한다.

관련 사례에 따르면 평균정확도가 96$로 상승했지만, 실제로는 오탐이 꽤 많이 나왔다고 한다. 아마 dt의 과적합 때문일듯

그래서 랜덤포레스트로 교체했다고 한다.

## 랜덤포레스트란?

많은 결정나무를 조합하는 앙상블 기반 알고리즘

다수의 dt는 분산학습(=정규화 효과)시키고 이들의 결정을 투표처럼 통합하는 방식
점수가 낮아도 안정적인 결과가 나온다고 한다.
즉, decision tree의 불안한 96% 성능보다
randomforest의 안정적인 95% 성능이 더 나은듯

sklearn에서 randomforest는 decisiontree와 거의 똑같이 사용가능하다. `max_depth`, `min_samples_leaf` 등 결정나무와 연관된
파라미터들이 있고, `n_estimator`는 결정트리 몇개를 사용할지 결정 -> 너무 크면 학습시간 오래 걸리고, 작으면 single DT와 비슷해버림

RF를 적용하여 최종적으로 100%의 정밀도(PRECISION)을 달성했다고 한다. 나느 ㄴ왜 안돼?';;


최종적인 피처의 중요도 중 눈에 띄는 것은

1. 복잡한 이름 : 랜덤계정명 생성 0.13
2. 퀘스트 종료 수 : 0.12
3. IP 최대 세션 수? : 0.23

이라고 한다.


## 개선 방향

검출된 결과로 학습 모델 개선 가능할 것이다. 개인적인 생각으로는 애매한 케이스에 대한 정확한 결과를 추적해서
어뷰징 유저는 놓치더라도, 정상유저를 어뷰징으로 오판하는 케이스를 줄이는 것이 핵심일 것 같다!

이후 나타날 변종 어뷰징 패턴에 대한 모니터링도 필요할듯



## 비지도 학습 방법

* 이제 막 서비스한 게임이라면 로그 데이터는 거의 축적된 것이 없을 것이다.
* 즉, 유저들의 로그 데이터는 수집하더라도, 그 데이터들에 대한 어뷰징 여부(0, 1)를 보여주는 라벨이 존재할 수 없다.

다른 사례에서는 K-MEANS 클러스터링으로 특성별 클러스터를 만들고, 어뷰징을 군집 시각화했다고 한다.

K-MEANS의 경우
- 피처를 표준화(Feature scaling)하고
- 휴리스틱하게 K 값을 지정(하이퍼파라미터)
- 클러스터 시각화

PCA를 이용하여 차원축소 후 시각화도 해봤다고 한다. 봇이 속한 클러스터가 뿔처럼 보인다고 하는데, 실제로 내가 2차원이나 3차원 공간에서
시각화했을 때는, 아주 명확해보이지는 않고, 애매모호하게 겹치는 영역이 보였다.

아무튼 pca가 잘된경우에 대한 설명을 보면, 분류하고자 하는 대상의 특성이 잘 드러나는 '피처'를 모으면, 저차원으로 차원축소시에 특성이 부각되는 것으로 추정
(pca 과정의 손실은 문제없나?)


## 사례3. 이상탐지(Anomaly Detection)

이상탐지는 데이터 분석을 통해 정상적이지 않은 (abnormal)한 케이스를 밝혀내는 것
예를 들면 결제관련 서비스에서 활용 - FDS(Fraud Detection System), 갑작스럽게 비정상적인 소비패턴을 보인다면 카드나 통장이 누군가에게 넘어갔을 가능성이 있음

이 분야에서는 비지도학습이 적절하다고 한다? -> 예외적인 것은 그 자체로 정의하기 어렵고, 자주 나타나지 않는 패턴이기 때문 (외계인 같다)

정확히 말하면 특이치 검출 vs 이상치 검출로 구분된다고 함.

* 특이치 검출(novelty detection) : 데이터가 오염되지 않았고, 자주 발생하지 않는 이상 탐지
- 이상치 검출(outlier detection) : 데이터가 오염되었을 가능성이 있고, 표준 분포를 따를 때?? (구분에 대해서는 추후 다시 공부)


게임머니 이상치 검출을 했다고 한다. 내가 했던 파밍검출과 비슷한 듯?

- Elliptic Envelope로 학습 후, 레벨/변동원인/변량의 그래프를 그렸는데 대부분의 유저는 10의 8승, 즉 +- 1억 변량 이내에 있으나 그것을 뛰어넘는 경우가 있었다고 한다. (엘립틱 엔벨로프가 모델이름인가? 공부해보자)

## 특이값 대응

정상범위 밖의 값들을 검출하긴 했으나, 부정 플레이에 대한 명확한 증거는 없다. (왜냐면 드문 패턴일 뿐이기 때문, 그 자체로 확정되는것은 아님)
그러므로 이후 모니터링의 대상이 되어 더 주의깊게 추적되어야하는것 같다.


# 느낀점

* 깊이있는 활용을 위해서는 기본 이론을 더 공부해야 한다고 한다.
- 좋은 가설(hypothesis)를 만들 수 있게 되고, 더 좋은 최적화 가능
- 하나 이상의 알고리즘을 사용해보고 비교하자. (우연히 내가 이것을 하게 되었다)
- 기계학습은 어뷰징 외에도 다양하게 활용가능


# 진행중?

AWS kINESIS로 APP 로그 수집중이라고 한다. (서비스 이름이 멋잇다. 키네시스?)
elasticsearch - 실시간 로그 모니터링, 엘라스틱서치라는 표현이 자주 나온다. 공부하자.


# advice

기계학습에 문제상황에 적합한지 판단해야 한다.
특성이 단순하면 고전적인 방법으로도 가능
eda로 특성파악을 먼저 하자.
학습모델에 따라 정규화/직교화 등이 필요할 수 있다.
클래스간 imbalance 문제 주의 (이부분 공부할 필요 있다! 생각보다 중요한 듯!)
의사연관(Spurious Correlation) - 실제로는 연관이 없지만, 있는 것처럼 보이는 경우, 단순히 데이터(숫자) 패턴만 보면 오판의 가능성이 있다.
특성의 세부사항까지 알고 판단해야 한다.










---

## 언더샘플링

## 클래스 불균형 문제

각각의 데이터 샘플이 속한 클래스의 비율이 지나치게 차이가 나면 (Highly-imbalanced Dataset) 단순히 우세한 클래스를 택하는 모형의 정확도가 높아지게 되어, 모델의 성능 판별이 어려워진다. 즉, 정확도(Accuracy)가 높아도 데이터 개수가 적은 클래스의 재현율(Recall-Rate)이 급격히 작아지는 현상이 발생할 수 있다. (아마 내가 처음에 클래스 불균형을 크게 고려하지 않고 했을 때, 상대적으로 적은 수의 정상유저를 어뷰저로 오판하는 케이스가 많았는데 그것이 이것과 관련된 현상인듯하다.)

이렇게 각 클래스에 속한 데이터 샘플의 양적 차이에 의해 발생하는 문제를 비대칭 데이터 문제(Imbalanced Data Problem), 또는 클래스 불균형(Class Imbalance) 문제라고 한다.

## 해결방법?

클래스 불균형 상황에서는 다수 클래스 데이터에서 일부만 사용하는 **언더샘플링**이나 소수 클래스 데이터를 증가시키는 **오버샘플링**을 사용하여 데이터 비율을 맞추면 정밀도(Precision)이 향상된다고 한다.

* 오버샘플링(Over-Sampling)
* 언더샘플링(Under-Sampling)
* 복합샘플링(Combining Over-and Under-Sampling)

당연한 말이지만, 클래스 불균형이 있는 상황에서 작은 클래스의 데이터를 쉽게 보충할 수 있었다면 애초에 문제가 아닐 것이다. 대부분의 머신러닝/딥러닝 프로젝트에서 학습 자원은 '거의 항상' 아무리 많아도 아쉬운 자원이다. 따라서 평범하게 생각할 수 있는 것은 언더샘플링일텐데, 나는 단순히 숫자만 맞추는 것을 생각했지만, 공부해보니 의외로 '효율적으로' 언더샘플링하는 방식들이 있어서 매우 흥미로웠다. (정말 별의별게 다 연구되어 있구나 ㅡㅡ;)

* `RandomUnderSampler` : Random Under-Sampling Method, 무작위 언더샘플링
* `TomekLinks` : Tomek's Link Method, 토멕 링크 방법
* `CondensedNearestNeighbour` : Condensed Nearest Neighbour Method
* `OneSidedSelection` : Under-Sampling based on One-sided Selection Method



### Random Under-Sampling

* 무작위로 데이터를 없애는 단순 샘플링이다.




### Tomek's Link Method

토멕링크(Tomek's Link)란 서로 다른 클래스에 속하는 한 쌍의 데이터 $(x_{+}, x_{-})$로 서로에게 더 가까운 다른 데이터가 존재하지 않는 것이다. 즉, 클래스가 서로 다른 두 데이터가 아주 가까이 붙어있으면 그 페어를 토멕링크라고 한다. 토멕링크 방법은 이러한 토멕링크를 찾은 다음 그 중에서 다수 클래스에 속하는 데이터를 제외하는 방법으로 경계선을 다수 클래스 쪽으로 밀어붙이는 효과가 있다.

즉, 굉장히 비슷한 특성을 갖고 있어서, 모델의 입장에서 분류하기 어려운 데이터 샘플을 추출하여 언더샘플링하는 방식 같다!!




### Condensed Nearest Neighbour

CNN(Condensed Nearest Neighbour) 방법은 1-NN 모형으로 분류되지 않는 데이터만 남기는 방법이다. 선택된 데이터 집합을 $S$라고 하자. 알고리즘은 다음과 같다.

1. 소수 클래스 데이터를 모두 $S$에 포함시킨다.
2. 다수 데이터 중에서 하나를 선택하여 가장 가까운 데이터가 다수 클래스에 속하면 제외하고, 아니면 $S$에 포함시킨다.
3. 더 이상 선택되는 데이터가 없을 때까지 과정 2를 반복한다.

이 방법을 사용하면 기존에 선택된 데이터와 가까이 있으면서 같은 클래스인 데이터는 선택되지 않기 때문에, 다수 데이터의 경우 선택되는 비율이 적어진다고 한다.


### One-sided Selection

One-sided Selection은 토멕링크 방법과 Condensed Nearest Neighbour 방법을 섞은 것이다. 토멕링크 중 다수 클래스를 제외하고 나머지 데이터 중에서도 서로 붙어있는 다수 클래스 데이터를 1-NN 방법으로 제외한다.



### Edited Nearest Neighbours

ENN(Edited Nearest Neighbours) 방법은 다수 클래스 데이터 중 가장 가까운 $k$개의 데이터가 다수 클래스가 아니면 삭제하는 방법이다. 소수 클래스 주변의 다수 클래스 데이터를 제거하는 효과가 있다고 한다.


### Neighbourhood Cleaning Rule

Neighbourhood Cleaning Rule 방법은 CNN(Condensed Nearest Neighbour) 방법과 ENN(Edited Nearest Neighbours) 방법을 섞은 것이다.



## 오버 샘플링

오버샘플링 알고리즘들은 대부분, 특정한 방식으로 소수 클래스의 데이터를 샘플링하는 방식인 것 같다. 그러나 이 방식이 얼마나 효과적인지는 솔직히 의문이다. 분명 효과가 있으니 알려진 방법들이겠지만, 솔직히 중요한 프로젝트에서 함부로 오버샘플링하여 유사데이터를 만드는 방식은 못할것 같다. 

알고리즘의 대부분이 소수 클래스 데이터를 모방하여, 그주변에 유사 데이터 포인트를 생성하는 방식인데, 낮은 차원의 데이터를 다루고, 분류곡면이 단순한 경우에는 어느 정도 효과가 있겠지만, 높은 차원의 특성공간에서 매우 복잡한 분류곡면(ex. manifold)이 있는 상황이라면 함부로 쓰지 못할 것 같다.


그래도 일단 이런게 있다는 것 정도는 알아두자.

* `RandomOverSampler` : Random Sampler
* `ADASYN` : Adaptive Synthetic Sampling Approach for Imbalanced Learning
* `SMOTE` : Synthetic Minority Over-Sampling Technique


### RandomOverSampler

Random Over Sampling은 소수 클래스의 데이터를 반복해서 넣는 것이다. 가중치를 증가시키는 것과 비슷한 효과라고 한다.



### ADASYN

ADASYN(Adaptive Synthetic Sampling) 방법은 소수 클래스 데이터와 그 데이터에서 가장 가까운 $k$개의 소수 클래스 데이터 중 무작위로 선택된 데이터 사이의 직선상에 가상의 소수 클래스 데이터를 만드는 방법이다.


---




## TIMESERIES의 정형 데이터 학습 방법








---

## What is Abusing?

게임 내의 불법행위인 어뷰징(Abusing)은 정확히 어느 정도까지의 부정행위를 의미하는가? 어뷰징의 대략적인 정의는 다음과 같은 것 같다.

* 게임의 기획 의도와 다르게 게임 정보를 대량 획득하거나 도움을 주는 행위
* 게임 자체의 버그
* 허용되지 않은 외부 프로그램(게임 핵)
* 약관에 위배되는 복수 계정 운용
* 채팅창 악성도배, 광고

등 서비스 구현에서 개발자의 의도를 벗어나는... 온갖 창의적인 트롤 플레이, 고의로 지는 패작 등을 다 포괄하는 것 같다.

나 같은 경우는, 군을 제대한 이후로는 온라인 게임은 거의하고 있지 않다. (사실 하고싶은데 워낙 바쁘고 공부할 것도 많아서 할 시간이 없다.) 가끔 인터넷에서 외국인들과 온라인 바둑을 두는 정도인데.. 심지어 이 고전적인 바둑게임에서조차도 이런 류의 어뷰징이 존재한다.. 예를 들면, 사람끼리 바둑을 둘 때, 자기보다 실력이 높은 상대와 싸워서 판이 불리하게되면, 갑자기 바둑인공지능의 힘을 빌리거나(... 고스트바둑왕의 사이빙의), 일부러 고의적인 패를 하여 스스로의 점수를 낮추고, 왕초보처럼 보이게 한 상태에서, 고수에게 대국신청을 하고, 본실력(..)을 발휘해서 이김으로써 상대방에게 엄청난 점수폭락을 유도하는 행위, 그리고 누가봐도 도저히 이길 가능성이 없는데, 상대방의 계가(집을 세고 게임을 끝내자는 신청) 행위를 무시하고, 의미없는 수를 두며 시간을 엄청끄는 플레이 등이 있다.

비슷한 용어로 치팅(Cheating)도 있다고 한다. 예전에 게임 소설을 보면 '치사할 정도로 강한 유저'를 '너 치트(Cheat) 잖아'라고 하던데, 아마 이와 관련된 용어 같다.
[Dinh & Nguyen (2016)](https://www.researchgate.net/publication/309159777_An_Empirical_Study_of_Anomaly_Detection_in_Online_Games?_sg=7-Jt9zdR8-pI7GOAnPMFWoztGn_-KnP1g2gX0Fv_wyO6ELrdUbo8qYwSQ7fgNQQRN9r_O2aHiEtkKBo)에 따르면 온라인 게임에서의 치팅은 '다른 사용자에 비해 이득을 취하기 위해 게임 경험을 수정하는 일련의 행동'으로 정의된다.


아마 오늘날 각각의 게임유저들이 하는 이런 트롤 플레이는 게임사가 그렇게까지 대단하게 볼 것 같지는 않다. 게임관련 방송을 보면, 요즘 주로 문제가 되는 것은 주로 자동화된 프로그램에 의해 수행되는 어뷰징 전용 핵 또는 봇일 것이다. 이런 방식의 어뷰징은 사람이 하는 것과는 비교도 되지 않을 것이다. 24시간 지치지도 않고, 온갖 게임의도에 어긋나는 행위를 하며, (아마도 수익을 발생시키기 위해) 끊임없이 작동하기 때문이다. 이런 어뷰저와 게임 개발자가 직접 상대하는 것은 아무리 봐도 게임 개발자가 사람이므로 불리할 것 같다.

그래서 요즘은 발전된 머신러닝 기술을 바탕으로 이러한 어뷰징을 자동 학습, 탐지, 제제하는 프로세스가 발전되고 있는 것 같다. 

참고로 나는 몰랐는데, '파밍'이라는 아이템을 수집하는 행위도 어뷰징에 포함된다고 한다... (근데 이러면 한국인 유저들 대부분이 다 제제되지 않나?? ㅋㅋ)


## Studies on Game Bot Detection

* Client-Side : 게임봇 프로그램 이름, 프로세스 정보, 메모리 상태 정보 등을 이용해 탐지하는 방법. but 해커들에게 쉽게 우회될 수 있고, 봇들을 잡기 위해 추가적인 anti-bot 프로그램을 운용해야해서 선호되지 않는다고 한다.

* Network-Side : 네트워크 프로토콜의 변화나 네트워크 트래픽을 모니터링하는 방법. 그러나 네트워크 과부하나 lag 위험성이 있어서 한계

* Server-Side : 게임 서버로부터 로그 데이터를 얻어 분석하는 방법. 로그를 통해서 데이터를 분석하고, 원하는 만큼 게임봇을 제제할 수 있기 때문에 게임회사에서 가장 쉽게 사용되는 방법. (아마 내가 받은 데이터도 서버 사이드에서 수집된 게임 로그 데이터가 아닐까?)


그럼 어떻게 게임봇을 탐지할까?

크게 2가지인듯

1. 유저와 게임봇의 특징들을 분석해 피처를 추출하여 **지도학습 기반의 분류**를 하는 것
2. 게임봇을 쓴 유저를 이상치로 간주하여 **비지도학습 기반의 이상 탐지**를 하는 것

그러나 분석을 위해서는 **잘 정제된 데이터**가 필요. 따라서 다음 5단계 거친다.

1. 서버에서 실시간 게임 로그 수집
2. 탐색적 데이터 분석
3. 특성 추출 및 개발
4. 분류나 이상탐지 등으로 분석
5. 모형 평가



---










## Reference

* 언더샘플링 : https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html
* Abusing Detection in Online Games [1]- Game Bot Detection with Machine Learning : https://assaeunji.github.io/machine%20learning/2020-03-29-gamebot/
